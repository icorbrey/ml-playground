{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Loss\n",
    "\n",
    "**Training** a model simply means learning (determining) good values for all the\n",
    "weights and the bias from labeled examples. In supervised learning, a machine\n",
    "learning algorithm builds a model by examining many examples and attempting to\n",
    "find a model that minimizes loss; this process is called **empirical risk**\n",
    "**minimization**.\n",
    "\n",
    "Loss is the penalty for a bad prediction. That is, **loss** is a number\n",
    "indicating how bad the model's prediction was on a single example. If the\n",
    "model's prediction is perfect, the loss is zero; otherwise, the loss is greater.\n",
    "The goal of training a model is to find a set of weights and biases that have\n",
    "_low_ loss, on average, across all examples.\n",
    "\n",
    "The linear regression models we'll examine here use a loss function called\n",
    "**squared loss** (also known as **$L_2$ loss**). The squared loss for a single\n",
    "example is as such: $L_2 = (y - y\\prime)^2$.\n",
    "\n",
    "**Mean square error (MSE)** is the average squared loss per example over the\n",
    "whole dataset. To calculate MSE, sum up all the squared losses for individual\n",
    "examples and then divide by the number of examples, as such: $MSE = \\frac{1}{N}\n",
    "\\sum_{(x, y) \\in D}{(y - prediction(x))^2}$, where:\n",
    "\n",
    "- $(x, y)$ is an example in which\n",
    "  - $x$ is the set of features (for example, chirps/minute, age, gender) that\n",
    "    the model uses to make predictions.\n",
    "  - $y$ is the example's label (for example, temperature).\n",
    "- $prediction(x)$ is a function of the weights and bias in combination with the\n",
    "  set of features $x$.\n",
    "- $D$ is a data set containing many labeled examples, which are $(x, y)$ pairs.\n",
    "- $N$ is the number of examples in $D$.\n",
    "\n",
    "Although MSE is commonly used in machine learning, it is neither the only\n",
    "practical loss function nor the best loss function for all circumstances."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
